{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bb1360ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: composable in /home/wil/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (0.4.0)\n",
      "Collecting composable\n",
      "  Downloading composable-0.5.3-py3-none-any.whl (7.5 kB)\n",
      "Requirement already satisfied: python-forge<19.0,>=18.6 in /home/wil/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from composable) (18.6.0)\n",
      "Requirement already satisfied: toolz<0.12.0,>=0.11.1 in /home/wil/.pyenv/versions/anaconda3-2022.05/lib/python3.9/site-packages (from composable) (0.11.2)\n",
      "Installing collected packages: composable\n",
      "  Attempting uninstall: composable\n",
      "    Found existing installation: composable 0.4.0\n",
      "    Uninstalling composable-0.4.0:\n",
      "      Successfully uninstalled composable-0.4.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "more-dfply 0.2.10 requires composable<0.3.0,>=0.2.5, but you have composable 0.5.3 which is incompatible.\u001b[0m\n",
      "Successfully installed composable-0.5.3\n"
     ]
    }
   ],
   "source": [
    "!pip install composable --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0ea06e",
   "metadata": {},
   "source": [
    "# Lab 1 - Getting Started\n",
    "\n",
    "## Project Overview\n",
    "\n",
    "In this project, you will use `pyspark` to process the data from the MinneMUDAC 2016 competition Dive into Water Data.  While the MinneMUDAC 2016 site, is no longer live, a copy was obtained using the [Wayback Machine (https://web.archive.org) and has been provided in [the overview notebook](./MinneMUDAC_2016_Overview.ipynb).  You should document your work in a Jupyter notebook, which will be used to submit your solution.\n",
    "\n",
    "## Lab 1 Tasks\n",
    "\n",
    "In this lab, you will perform the following tasks\n",
    "\n",
    "1. Download and unzip the data.\n",
    "2. Investigating the columns in various property data files.\n",
    "\n",
    "### Task 1 - Data download and unzip\n",
    "\n",
    "While the download links on the original site no longer work, you can access the data using [this link](https://mnscu-my.sharepoint.com/:u:/g/personal/bn8210wy_minnstate_edu/EdUePet8JsdKv5aUt9gvjoMBxQhXrOx73WpQyVNwLVDfkA?e=rR8qrc)\n",
    "**Note.** You should have already downloaded the zip file as part of the previous activity.\n",
    "\n",
    "1. Move the zip file unto your repository\n",
    "2. Unzip and move the files into your data folder.\n",
    "\n",
    "**Hint.** Take a look the the Colab section of any module 5 lecture for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "468694f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MinneMUDAC_raw_files  MinneMUDAC_raw_files.zip\n"
     ]
    }
   ],
   "source": [
    "# use ls to inspect the data file.\n",
    "!ls ./data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "d49e1959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use unzip to unzip the lakes data zip\n",
    "## unziped data using explorer.exe ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "190cb325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/mces_lakes_1999_2014.txt\n"
     ]
    }
   ],
   "source": [
    "# use ls to inspect the lake folder found in the data folder.\n",
    "!ls ./data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/mces_lakes_1999_2014.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81c92d9",
   "metadata": {},
   "source": [
    "#### Questions\n",
    "\n",
    "1. Notice that we have multiple property files, one per year.  What verb(s) will be used to combine these files?\n",
    "2. Why is it important to compare the columns of these files?\n",
    "3. Use `!head path` to inspect the first few lines of one of the files.  How are the columns separated?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ca4c23",
   "metadata": {},
   "source": [
    "> <font color=\"orange\"> union the tables, we want to see all the time development from the data in the colums </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9f1a449",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "head: cannot open 'path' for reading: No such file or directory\n",
      "==> ./data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/2002_metro_tax_parcels.txt <==\n",
      "ACRES_DEED|ACRES_POLY|AGPRE_ENRD|AGPRE_EXPD|AG_PRESERV|BASEMENT|BLDG_NUM|BLOCK|CITY|CITY_USPS|COOLING|COUNTY_ID|DWELL_TYPE|EMV_BLDG|EMV_LAND|EMV_TOTAL|FIN_SQ_FT|GARAGE|GARAGESQFT|GREEN_ACRE|HEATING|HOMESTEAD|HOME_STYLE|LANDMARK|LOT|MULTI_USES|NUM_UNITS|OPEN_SPACE|OWNER_MORE|OWNER_NAME|OWN_ADD_L1|OWN_ADD_L2|OWN_ADD_L3|OWN_NAME|PARC_CODE|PIN|PIN_1|PLAT_NAME|PREFIXTYPE|PREFIX_DIR|SALE_DATE|SALE_VALUE|SCHOOL_DST|SPEC_ASSES|STREET|STREETNAME|STREETTYPE|STRUC_TYPE|SUFFIX_DIR|Shape_Area|Shape_Leng|TAX_ADD_L1|TAX_ADD_L2|TAX_ADD_L3|TAX_ADD_LI|TAX_CAPAC|TAX_EXEMPT|TAX_NAME|TOTAL_TAX|UNIT_INFO|USE1_DESC|USE2_DESC|USE3_DESC|USE4_DESC|WSHD_DIST|XUSE1_DESC|XUSE2_DESC|XUSE3_DESC|XUSE4_DESC|YEAR_BUILT|Year|ZIP|ZIP4|centroid_lat|centroid_long\n",
      "||||||14195||ANDOVER|||003||222460.0|55510.0|292596.0||||||Y|||||||||14195 ALDER ST NW||ANDOVER, MN 55304||0.0|003-253224440139|||||2000-11-17|295547.0|11||14195 ALDER ST NW|||RAMBLER BASEMENT||630.998818085|103.296560124|14195 ALDER ST NW||ANDOVER, MN 55304||2566.0|N||2621.0||||||COON CREEK WATERSHED DISTRICT|||||2000.0|2002|55304||45.22909|-93.26612\n",
      "||||||14189||ANDOVER|||003||228185.0|51240.0|295572.0||||||Y|||||||||14189 ALDER ST NW||ANDOVER, MN 55304||0.0|003-253224440138|||||2000-04-28|288699.0|11||14189 ALDER ST NW|||DET. PT-RAMBLER BSMT||618.552705616|102.967952506|801 MARQUETTE AVE||MPLS, MN 55402||2648.0|N||2715.0||||||COON CREEK WATERSHED DISTRICT|||||1999.0|2002|55304||45.22895|-93.26596\n",
      "||||||14177||ANDOVER|||003||213657.0|51240.0|286457.0||||||Y|||||||||14177 ALDER ST NW||ANDOVER, MN 55304||0.0|003-253224440136|||||2000-03-31|259445.0|11||14177 ALDER ST NW|||DET. PT-RAMBLER BSMT||584.639926739|99.612228932|14177 ALDER ST NW||ANDOVER, MN 55304||2550.0|N||2602.0||||||COON CREEK WATERSHED DISTRICT|||||1999.0|2002|55304||45.22867|-93.26571\n",
      "||||||14165||ANDOVER|||003||205653.0|51240.0|270221.0||||||Y|||||||||14165 ALDER ST NW||ANDOVER, MN 55304||0.0|003-253224440134|||||1999-11-24|240035.0|11||14165 ALDER ST NW|||DET. PT-RAMBLER BSMT||647.930828798|104.297724009|14165 ALDER ST NW||ANDOVER, MN 55304||2390.0|N||2418.0||||||COON CREEK WATERSHED DISTRICT|||||1999.0|2002|55304||45.22832|-93.26552\n",
      "||||||14159||ANDOVER|||003||192319.0|51240.0|266522.0||||||Y|||||||||14159 ALDER ST NW||ANDOVR, MN 55304||0.0|003-253224440133|||||2000-07-28|254450.0|11||14159 ALDER ST NW|||DET. PT-RAMBLER BSMT||533.65953398|96.2498784782|14159 ALDER ST NW||ANDOVR, MN 55304||2367.0|N||2391.0||||||COON CREEK WATERSHED DISTRICT|||||2000.0|2002|55304||45.22815|-93.26553\n",
      "||||||||ANDOVER|||003||0.0|51240.0|51240.0||||||N|||||||||14180 ALDER ST NW||ANDOVER, MN 55304||0.0|003-253224440170|||||2002-07-26|300065.0|11|||||||652.486413472|104.527309171|4242 N HARLEM AVE||NORRIDGE, IL 60706||323.0|N||341.0||||||COON CREEK WATERSHED DISTRICT|||||0.0|2002|||45.22862|-93.26646\n",
      "||||||||ANDOVER|||003||0.0|51240.0|51240.0||||||N|||||||||14168 ALDER ST NW||ANDOVER, MN 55304||0.0|003-253224440172|||||2002-07-29|295200.0|11|||||||532.629183969|96.6456894301|14168 ALDER ST NW||ANDOVER, MN 55304||323.0|N||341.0||||||COON CREEK WATERSHED DISTRICT|||||0.0|2002|||45.22831|-93.2663\n",
      "||||||||ANDOVER|||003||0.0|51240.0|51240.0||||||N|||||||||1875 COMMERCIAL BLVD NW|#1|ANDOVER, MN 55304||0.0|003-253224440166||||||0.0|11|||||||568.529227999|99.4544755823|1875 COMMERCIAL BLVD NW|#1|ANDOVER, MN 55304||323.0|N||341.0||||||COON CREEK WATERSHED DISTRICT|||||0.0|2002|||45.22873|-93.26752\n",
      "||||||76||ANDOVER|||003||73568.0|51240.0|140428.0||||||N|||||||||76 142ND AVE NW||ANDOVER, MN 55304||0.0|003-253224440168|||||2002-04-09|212862.0|11||76 142ND AVE NW|||DET. PT-RAMBLER SLAB||581.709920174|100.536058309|76 142ND AVE NW||ANDOVER, MN 55304||323.0|N||341.0||||||COON CREEK WATERSHED DISTRICT|||||2001.0|2002|||45.22882|-93.26709\n",
      "head: cannot open 'path' for reading: No such file or directory\n",
      "==> ./data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/2003_metro_tax_parcels.txt <==\n",
      "BLDG_NUM|CITY|COUNTY_ID|EMV_BLDG|EMV_LAND|EMV_TOTAL|HOMESTEAD|NUM_UNITS|OWN_ADD_L1|OWN_ADD_L2|OWN_ADD_L3|OWN_NAME|PARC_CODE|PIN|SALE_DATE|SALE_VALUE|SCHOOL_DST|STREET|STRUC_TYPE|Shape_Area|Shape_Leng|TAX_ADD_L1|TAX_ADD_L2|TAX_ADD_L3|TAX_CAPAC|TAX_EXEMPT|TAX_NAME|TOTAL_TAX|WSHD_DIST|YEAR_BUILT|Year|ZIP|centroid_long|centroid_lat\n",
      "|ST FRANCIS|003|0.0|17750.0|23398.0|N||24457 DOGWOOD ST NW||BETHEL, MN 55005||0.0|003-253424110001||0.0|15||OVERRIDE STRUCTURE|32468.8805894|1340.1976685|24457 DOGWOOD ST NW||BETHEL, MN 55005|351.0|N||614.0|UPPER RUM RIVER WMO|1980.0|2003||-93.26744|45.41336\n",
      "24457|ST FRANCIS|003|101672.0|36700.0|147468.0|Y||24457 DOGWOOD ST NW||BETHEL, MN 55005||0.0|003-253424110002||0.0|15|DOGWOOD ST NW|SPLIT FOYER|3744.3683136|252.61429213|24457 DOGWOOD ST NW||BETHEL, MN 55005|1321.0|N||1319.0|UPPER RUM RIVER WMO|1974.0|2003|55005|-93.27015|45.41357\n",
      "24442|ST FRANCIS|003|94087.0|57576.0|165053.0|Y||24442 DOGWOOD ST NW||ST FRANCIS, MN 55005||0.0|003-253424120001|2001-04-26|215000.0|15|DOGWOOD ST NW|SPLIT FOYER|35393.01132|1005.69993359|1757 TAPO CANYON RD SV-24 #300||SIMI VALLEY, CA 93063|1416.0|N||1439.0|UPPER RUM RIVER WMO|1969.0|2003|55005|-93.27349|45.41322\n",
      "410|ST FRANCIS|003|113486.0|48700.0|174371.0|Y||PO BOX 14||BETHEL, MN 55005||0.0|003-253424210002|1995-03-23|101000.0|15|245TH AVE NW|EXPANSION|45148.9538967|1030.60449705|14528 SO OUTER FORTY RD||CHESTERFIELD, MO 63017|1706.0|N||1802.0|UPPER RUM RIVER WMO|1989.0|2003|55005|-93.27689|45.41171\n",
      "480|ST FRANCIS|003|107054.0|47450.0|163513.0|Y||480 245TH AVE NW||EAST BETHEL, MN 55005||0.0|003-253424210003|1995-04-04|101900.0|15|245TH AVE NW|SPLIT FOYER|58450.3343939|1093.02202679|480 245TH AVE NW||EAST BETHEL, MN 55005|1494.0|N||1536.0|UPPER RUM RIVER WMO|1995.0|2003|55070|-93.27854|45.41173\n",
      "|ST FRANCIS|003|0.0|107500.0|107500.0|N||500 LAFAYETTE RD||ST PAUL, MN 55155||0.0|003-263424210001||0.0|15|||332079.090668|2467.39584844|500 LAFAYETTE RD||ST PAUL, MN 55155|0.0|Y||0.0|UPPER RUM RIVER WMO|0.0|2003||-93.2989|45.40984\n",
      "|ST FRANCIS|003|0.0|10005.0|10005.0|N||550 245TH AVE NW||ISANTI, MN 55040||0.0|003-253424210004|1987-02-01|0.0|15|||18954.0746978|892.402762151|14528 SO OUTER FORTY DR||CHESTERFIELD, MO 63017|58.0|N||67.0|UPPER RUM RIVER WMO|0.0|2003||-93.27978|45.41176\n",
      "550|ST FRANCIS|003|79558.0|35060.0|120869.0|Y||550 245TH AVE NE||ISANTI, MN 55040||0.0|003-253424210005|1987-02-01|0.0|15|245TH AVE NW|SPLIT FOYER|18565.1905781|888.839502999|14528 SO OUTER FORTY DR||CHESTERFIELD, MO 63017|1126.0|N||1080.0|UPPER RUM RIVER WMO|1969.0|2003|55040|-93.28038|45.41172\n",
      "|ST FRANCIS|003|0.0|11930.0|11930.0|N||900 NCL TOWER||ST PAUL, MN 55101||0.0|003-253424210006|1995-06-07|0.0|15|||17321.4405218|881.12290077|900 NCL TOWER||ST PAUL, MN 55101|0.0|Y||0.0|UPPER RUM RIVER WMO|0.0|2003||-93.28096|45.41173\n"
     ]
    }
   ],
   "source": [
    "# Use `!head path` to inspect the first few lines of one of the files.\n",
    "!head path ./data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/2002_metro_tax_parcels.txt\n",
    "!head path ./data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/2003_metro_tax_parcels.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac3de1bd",
   "metadata": {},
   "source": [
    "## Task 2 - Create a table summarizing the columns from each table.\n",
    "\n",
    "<img src=\"./img/column_master_file.png\" width=\"800\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70292453",
   "metadata": {},
   "source": [
    "**Hints.**\n",
    "\n",
    "1. Use `glob` to get a list of all the parcel files.\n",
    "2. Write a function that takes a parcel file path as input and returns just the year (as a string).\n",
    "3. Use a list comprehension contains pairs of value of the form `(year, df)` where `df` a `pyspark` data frame for each file. Although the files are large, remember that `pyspark` is lazy and will do minimal work on this step.\n",
    "4. We need to create some initial data frame that contain the columns labels in one column and an indicator for the respective year.  I did that with a list comprehension that named both elements from the last list using `[ ... for year, df in list_name]`.  I found it easiest to use `pandas` to create the data frame.  This was tricky, so I have provided my helper function below.\n",
    "5. Next, we need to create a master data frame that contains all possible column labels in a `\"columns\"` column. Do this using `reduce` to union all dataframes together after selecting just the `\"columns\"` column of each.  Use `distinct` to remove repeat column labels.\n",
    "6. Finally, we want to join each of the yearly data frames into the master column data frame.  Do this using `reduce` using \n",
    "    * the master column dataframe as the initial value\n",
    "    * A left join on the `\"columns'` columns.\n",
    "7. Write the resulting file out to a CSV and inspect the results.  Use this files to answer questions in part 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2b50c221",
   "metadata": {},
   "outputs": [],
   "source": [
    "from composable.sequence import reduce\n",
    "from more_pyspark import to_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ba6c17a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/2002_metro_tax_parcels.txt',\n",
       " './data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/2003_metro_tax_parcels.txt',\n",
       " './data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/2004_metro_tax_parcels.txt',\n",
       " './data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/2005_metro_tax_parcels.txt',\n",
       " './data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/2006_metro_tax_parcels.txt',\n",
       " './data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/2007_metro_tax_parcels.txt',\n",
       " './data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/2008_metro_tax_parcels.txt',\n",
       " './data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/2009_metro_tax_parcels.txt',\n",
       " './data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/2010_metro_tax_parcels.txt',\n",
       " './data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/2011_metro_tax_parcels.txt',\n",
       " './data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/2012_metro_tax_parcels.txt',\n",
       " './data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/2013_metro_tax_parcels.txt',\n",
       " './data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/2014_metro_tax_parcels.txt',\n",
       " './data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/2015_metro_tax_parcels.txt']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 1\n",
    "\n",
    "from glob import glob as orignal_glob\n",
    "from composable import pipeable\n",
    "from pyspark.sql.functions import lit\n",
    "glob = pipeable(orignal_glob)\n",
    "parcel_files = sorted(glob('./data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/*parcel*.txt'))\n",
    "parcel_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f3e6b7c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for creating yearly column dataframes in step **4.**\n",
    "from pyspark.sql.functions import lit\n",
    "import pandas as pd\n",
    "make_column_df = lambda year, df: (spark.createDataFrame(pd.DataFrame({'columns':df.columns}))\n",
    "                                        .select('columns', lit(1).alias(year)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8e98f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hey = reduce(make_column_df, hello, parcel_files)\n",
    "# .union(df.select).distinct()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24b13f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/15 11:10:28 WARN Utils: Your hostname, lu4543hm221 resolves to a loopback address: 127.0.1.1; using 172.17.179.232 instead (on interface eth0)\n",
      "22/11/15 11:10:28 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/11/15 11:10:29 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "import re\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('Ops').getOrCreate()\n",
    "compile_year = re.compile('./data/MinneMUDAC_raw_files/MinneMUDAC_raw_files/(\\d{4})_metro_tax_parcels.txt')\n",
    "get_year = lambda path: compile_year.search(path).group(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ac5b04db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '2015']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 2\n",
    "\n",
    "years = [get_year(path) for path in parcel_files]\n",
    "years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d84a581f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#step 3\n",
    "\n",
    "year_w_df = [(get_year(path), spark.read.csv(path, sep='|',header=True))\n",
    "    for path in parcel_files]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "70061189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[DataFrame[columns: string, 2002: int],\n",
       " DataFrame[columns: string, 2003: int],\n",
       " DataFrame[columns: string, 2004: int],\n",
       " DataFrame[columns: string, 2005: int],\n",
       " DataFrame[columns: string, 2006: int],\n",
       " DataFrame[columns: string, 2007: int],\n",
       " DataFrame[columns: string, 2008: int],\n",
       " DataFrame[columns: string, 2009: int],\n",
       " DataFrame[columns: string, 2010: int],\n",
       " DataFrame[columns: string, 2011: int],\n",
       " DataFrame[columns: string, 2012: int],\n",
       " DataFrame[columns: string, 2013: int],\n",
       " DataFrame[columns: string, 2014: int],\n",
       " DataFrame[columns: string, 2015: int]]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyparkdf = [make_column_df(path,df) for path, df in year_w_df]\n",
    "pyparkdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "db681fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ACRES_POLY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ACRES_DEED</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CITY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BLDG_NUM</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BLOCK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Homestead24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Shape_STLe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Shape_STAr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Shape_Le_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>TORRENS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        columns\n",
       "0    ACRES_POLY\n",
       "1    ACRES_DEED\n",
       "2          CITY\n",
       "3      BLDG_NUM\n",
       "4         BLOCK\n",
       "..          ...\n",
       "79  Homestead24\n",
       "80   Shape_STLe\n",
       "81   Shape_STAr\n",
       "82   Shape_Le_1\n",
       "83      TORRENS\n",
       "\n",
       "[84 rows x 1 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# step 5\n",
    "from composable.sequence import reduce\n",
    "\n",
    "mast = (pyparkdf\n",
    "        >> reduce(lambda acc, df: (acc.union(df).distinct()))).drop('2002')\n",
    "mast.collect() >> to_pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "bce9273c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>columns</th>\n",
       "      <th>2002</th>\n",
       "      <th>2003</th>\n",
       "      <th>2004</th>\n",
       "      <th>2005</th>\n",
       "      <th>2006</th>\n",
       "      <th>2007</th>\n",
       "      <th>2008</th>\n",
       "      <th>2009</th>\n",
       "      <th>2010</th>\n",
       "      <th>2011</th>\n",
       "      <th>2012</th>\n",
       "      <th>2013</th>\n",
       "      <th>2014</th>\n",
       "      <th>2015</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Shape_Area</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>COOLING</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PREFIXTYPE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>OWN_ADD_L2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Homestead24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>GARAGE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>centroid_long</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>USE1_DESC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>SALE_VALUE</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>EMV_TOTAL</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>84 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          columns  2002  2003  2004  2005  ...  2011  2012  2013  2014  2015\n",
       "0      Shape_Area   1.0   1.0   1.0   1.0  ...   1.0   1.0   1.0   1.0   1.0\n",
       "1         COOLING   1.0   NaN   1.0   1.0  ...   1.0   1.0   1.0   1.0   1.0\n",
       "2      PREFIXTYPE   1.0   NaN   1.0   1.0  ...   1.0   1.0   1.0   1.0   1.0\n",
       "3      OWN_ADD_L2   1.0   1.0   1.0   1.0  ...   1.0   1.0   1.0   1.0   1.0\n",
       "4     Homestead24   NaN   NaN   NaN   NaN  ...   NaN   NaN   NaN   NaN   NaN\n",
       "..            ...   ...   ...   ...   ...  ...   ...   ...   ...   ...   ...\n",
       "79         GARAGE   1.0   NaN   1.0   1.0  ...   1.0   1.0   1.0   1.0   1.0\n",
       "80  centroid_long   1.0   1.0   1.0   1.0  ...   1.0   1.0   1.0   1.0   1.0\n",
       "81      USE1_DESC   1.0   NaN   1.0   1.0  ...   1.0   1.0   1.0   1.0   1.0\n",
       "82     SALE_VALUE   1.0   1.0   1.0   1.0  ...   1.0   1.0   1.0   1.0   1.0\n",
       "83      EMV_TOTAL   1.0   1.0   1.0   1.0  ...   1.0   1.0   1.0   1.0   1.0\n",
       "\n",
       "[84 rows x 15 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part1final = reduce(lambda acc, df: acc.join(df, on ='columns', how = 'left'), pyparkdf, init=mast)\n",
    "part1final.collect() >> to_pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09a4f4b",
   "metadata": {},
   "source": [
    "### Part 2 -- Inspecting and comparing the columns\n",
    "\n",
    "**Goal.** Find a interval of years that\n",
    "\n",
    "1. Cover a large amount of time.\n",
    "2. Contain as many common columns as possible.\n",
    "\n",
    "**Task.** Inspect the column summary table and discuss what you find.  Suggest a time frame that satisfies our competing goals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "02f97ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sum(2002)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sum(2002)\n",
       "0         75"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import mean, stddev, col, sum\n",
    "\n",
    "(part1final.agg(sum('2002'))\n",
    "                .collect()) >>to_pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "474e8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write to csv\n",
    "\n",
    "part1final.toPandas().to_csv('./data/part1final')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b293c2",
   "metadata": {},
   "source": [
    "#### Your conclusions\n",
    "\n",
    "<font color=\"orange\">\n",
    "this is nastyyyyyy, 2002 had the most in that year, 2007 to 2009 had the most columns\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b27d183a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "14ab39836ad45f9872a4fbaf347177c599900dde8b629b89551b87d8978983f4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
